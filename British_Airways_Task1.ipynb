{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fady-Emeel/British-Airways-virtual-internship/blob/main/British_Airways_Task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a9Izwwb9pdH"
      },
      "source": [
        "# Task 1\n",
        "\n",
        "---\n",
        "\n",
        "## Web scraping and analysis\n",
        "\n",
        "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
        "\n",
        "### Scraping data from Skytrax\n",
        "\n",
        "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
        "\n",
        "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nN_b_sm89pdI"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Rg_RgY-9pdJ",
        "outputId": "93a12fa5-ee64-446a-fc5e-7ae1b3a71639"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraping page 1\n",
            "   ---> 100 total reviews\n",
            "Scraping page 2\n",
            "   ---> 200 total reviews\n",
            "Scraping page 3\n",
            "   ---> 300 total reviews\n",
            "Scraping page 4\n",
            "   ---> 400 total reviews\n",
            "Scraping page 5\n",
            "   ---> 500 total reviews\n",
            "Scraping page 6\n",
            "   ---> 600 total reviews\n",
            "Scraping page 7\n",
            "   ---> 700 total reviews\n",
            "Scraping page 8\n",
            "   ---> 800 total reviews\n",
            "Scraping page 9\n",
            "   ---> 900 total reviews\n",
            "Scraping page 10\n",
            "   ---> 1000 total reviews\n",
            "Scraping page 11\n",
            "   ---> 1100 total reviews\n",
            "Scraping page 12\n",
            "   ---> 1200 total reviews\n",
            "Scraping page 13\n",
            "   ---> 1300 total reviews\n",
            "Scraping page 14\n",
            "   ---> 1400 total reviews\n",
            "Scraping page 15\n",
            "   ---> 1500 total reviews\n",
            "Scraping page 16\n",
            "   ---> 1600 total reviews\n",
            "Scraping page 17\n",
            "   ---> 1700 total reviews\n",
            "Scraping page 18\n",
            "   ---> 1800 total reviews\n",
            "Scraping page 19\n",
            "   ---> 1900 total reviews\n",
            "Scraping page 20\n",
            "   ---> 2000 total reviews\n"
          ]
        }
      ],
      "source": [
        "# Set the URL of the paginated webpage that you want to scrape\n",
        "url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
        "\n",
        "# Initialize an empty list to store the data that you scrape\n",
        "data = []\n",
        "\n",
        "# Setting the initial page number and the increment that you want to use to paginate through the webpage\n",
        "page_num = 1\n",
        "page_incr = 1\n",
        "page_size = 100\n",
        "# maximum number of pages to be scraped\n",
        "max_pages = 20\n",
        "\n",
        "# Set the URL of the webpage to be scraped \n",
        "paginated_url = f\"{url}/page/{page_num}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
        "\n",
        "# A while loop to paginate through the webpage and scrape the data\n",
        "while page_num <= max_pages:\n",
        "\n",
        "    print(f\"Scraping page {page_num}\")\n",
        "\n",
        "    # A GET request to the paginated URL\n",
        "    response = requests.get(paginated_url)\n",
        "\n",
        "    # Parsing the response using BeautifulSoup\n",
        "    parsed_content = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Finding all the elements on the page that contain the data to be scraped\n",
        "    elements = parsed_content.find_all(\"div\",class_ = \"body\")\n",
        "\n",
        "    # Looping through the elements and extract the data that you want to scrape\n",
        "    for element in elements:\n",
        "        header = element.find(\"h2\",class_ = \"text_header\").text.replace(\"\\n\", \" \")\n",
        "        sub_header = element.find(\"h3\",class_ = \"text_sub_header\").text.replace(\"\\n\", \" \")\n",
        "        content = element.find(\"div\",class_ = \"text_content\").text.replace(\"\\n\", \" \")\n",
        "        \n",
        "        data.append([header,sub_header,content])\n",
        "\n",
        "    # Increasing the page number and setting the paginated URL to the new page\n",
        "    page_num += page_incr\n",
        "    paginated_url = f\"{url}/page/{page_num}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
        "\n",
        "    print(f\"   ---> {len(data)} total reviews\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyzsQT-T9pdK",
        "outputId": "6285f475-a7a2-4953-c318-d463760b056e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>REVIEW</th>\n",
              "      <th>PERSONAL INFO</th>\n",
              "      <th>CONTENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"Another bad show\"</td>\n",
              "      <td>Kathi Blanning (United States) 14th May 2023</td>\n",
              "      <td>Not Verified | Only the second time flying BA ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"what an earth is going on at BA\"</td>\n",
              "      <td>2 reviews    Harry Okin (United Kingdom) 14t...</td>\n",
              "      <td>I wasn't going to bother reviewing this flight...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"I had to reschedule my flight\"</td>\n",
              "      <td>Nicholas Felty (United States) 13th May 2023</td>\n",
              "      <td>I booked business class tickets for my fiancé ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"most appalling airline service\"</td>\n",
              "      <td>C Peale (Australia) 8th May 2023</td>\n",
              "      <td>I will never travel with British Airways again...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"Customer service is shocking\"</td>\n",
              "      <td>Jason Wickert (United Kingdom) 6th May 2023</td>\n",
              "      <td>I am already in Portugal so contacted them tod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>\"flight time should justify at least a sandwich\"</td>\n",
              "      <td>57 reviews    A Wong (China) 16th August 2016</td>\n",
              "      <td>✅ Verified Review | The flight from London Hea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>\"bag did not arrive into Dublin\"</td>\n",
              "      <td>Richard Tobin (United Kingdom) 16th August 2016</td>\n",
              "      <td>✅ Verified Review |  I was booked to travel Br...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>\"friendly and professional\"</td>\n",
              "      <td>B Richardson (United Kingdom) 14th August 2016</td>\n",
              "      <td>✅ Verified Review |  London Heathrow - Vancouv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>\"A380 is unconscionably crammed\"</td>\n",
              "      <td>W Jackson (United States) 14th August 2016</td>\n",
              "      <td>✅ Verified Review |  Flew London Heathrow to W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>\"no respect for economy travellers\"</td>\n",
              "      <td>R Anderson (United Kingdom) 14th August 2016</td>\n",
              "      <td>✅ Verified Review |  I fly this route 3-4 time...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                REVIEW  \\\n",
              "0                                   \"Another bad show\"   \n",
              "1                    \"what an earth is going on at BA\"   \n",
              "2                      \"I had to reschedule my flight\"   \n",
              "3                     \"most appalling airline service\"   \n",
              "4                       \"Customer service is shocking\"   \n",
              "...                                                ...   \n",
              "1995  \"flight time should justify at least a sandwich\"   \n",
              "1996                  \"bag did not arrive into Dublin\"   \n",
              "1997                       \"friendly and professional\"   \n",
              "1998                  \"A380 is unconscionably crammed\"   \n",
              "1999               \"no respect for economy travellers\"   \n",
              "\n",
              "                                          PERSONAL INFO  \\\n",
              "0          Kathi Blanning (United States) 14th May 2023   \n",
              "1       2 reviews    Harry Okin (United Kingdom) 14t...   \n",
              "2          Nicholas Felty (United States) 13th May 2023   \n",
              "3                      C Peale (Australia) 8th May 2023   \n",
              "4           Jason Wickert (United Kingdom) 6th May 2023   \n",
              "...                                                 ...   \n",
              "1995      57 reviews    A Wong (China) 16th August 2016   \n",
              "1996    Richard Tobin (United Kingdom) 16th August 2016   \n",
              "1997     B Richardson (United Kingdom) 14th August 2016   \n",
              "1998         W Jackson (United States) 14th August 2016   \n",
              "1999       R Anderson (United Kingdom) 14th August 2016   \n",
              "\n",
              "                                                CONTENT  \n",
              "0     Not Verified | Only the second time flying BA ...  \n",
              "1     I wasn't going to bother reviewing this flight...  \n",
              "2     I booked business class tickets for my fiancé ...  \n",
              "3     I will never travel with British Airways again...  \n",
              "4     I am already in Portugal so contacted them tod...  \n",
              "...                                                 ...  \n",
              "1995  ✅ Verified Review | The flight from London Hea...  \n",
              "1996  ✅ Verified Review |  I was booked to travel Br...  \n",
              "1997  ✅ Verified Review |  London Heathrow - Vancouv...  \n",
              "1998  ✅ Verified Review |  Flew London Heathrow to W...  \n",
              "1999  ✅ Verified Review |  I fly this route 3-4 time...  \n",
              "\n",
              "[2000 rows x 3 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Coverting the list data into a dataframe\n",
        "df = pd.DataFrame(data)\n",
        "df.columns = [\"REVIEW\",\"PERSONAL INFO\",\"CONTENT\"]\n",
        "\n",
        "#Removing unwanted text(first text preprocessing)\n",
        "df.replace(re.compile(r'\\s*✅ Trip Verified \\|\\s*'), '', inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FufvmvkF9pdK"
      },
      "outputs": [],
      "source": [
        "#Saving data into a csv\n",
        "df.to_csv(\"\\BA_reviews.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw94rQfZ9pdK"
      },
      "source": [
        "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
        "\n",
        " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quyhdskp9pdL",
        "outputId": "74392fb8-1d26-4599-f03f-38175f35b63d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CONTENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Not Verified | Only the second time flying BA ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I wasn't going to bother reviewing this flight...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I booked business class tickets for my fiancé ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I will never travel with British Airways again...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I am already in Portugal so contacted them tod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>The flight from London Heathrow to Krakow with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>I was booked to travel British Airways from He...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>London Heathrow - Vancouver - London Heathrow....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>Flew London Heathrow to Washington DC. The Bus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>I fly this route 3-4 times a year, unfortunate...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                CONTENT\n",
              "0     Not Verified | Only the second time flying BA ...\n",
              "1     I wasn't going to bother reviewing this flight...\n",
              "2     I booked business class tickets for my fiancé ...\n",
              "3     I will never travel with British Airways again...\n",
              "4     I am already in Portugal so contacted them tod...\n",
              "...                                                 ...\n",
              "1995  The flight from London Heathrow to Krakow with...\n",
              "1996  I was booked to travel British Airways from He...\n",
              "1997  London Heathrow - Vancouver - London Heathrow....\n",
              "1998  Flew London Heathrow to Washington DC. The Bus...\n",
              "1999  I fly this route 3-4 times a year, unfortunate...\n",
              "\n",
              "[2000 rows x 1 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_analysis_df = df.drop([\"REVIEW\",\"PERSONAL INFO\"], axis=1)\n",
        "sentiment_analysis_df.replace(re.compile(r'\\s*✅ Verified Review \\|\\s*'), '', inplace=True)\n",
        "sentiment_analysis_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1VpVqlF9pdL"
      },
      "outputs": [],
      "source": [
        "# Save the DataFrame to a CSV file\n",
        "sentiment_analysis_df.to_csv(\"sentiment_content.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}